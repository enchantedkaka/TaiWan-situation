import json
import os
import requests
import feedparser # <-- æ–°å¢ï¼šç”¨äºè§£æ RSS
import datetime
from datetime import datetime, timezone
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# --- V5 é…ç½®åŒº ---
DEEPSEEK_API_KEY = os.environ.get('DEEPSEEK_API_KEY')
NEWS_API_KEY = os.environ.get('NEWS_API_KEY')

DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"
NEWS_API_URL = "https://newsapi.org/v2/everything"
INDICATORS_FILE = "indicators.json"
SCORES_FILE = "scores-v3.json"

# è¡°å‡å› å­ (0.75 è¡¨ç¤ºæ¯å¤©è¡°å‡ 25%)
DECAY_FACTOR = 0.75
WEIGHT_FLOOR = 1

# --- 1. ç½‘ç»œè¯·æ±‚åŸºç¡€ ---

def create_retry_session():
    session = requests.Session()
    retry_strategy = Retry(
        total=3, status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET"], backoff_factor=1
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    return session

# --- 2. æ•°æ®è·å–æ¨¡å— ---

# A. å›½é™…/å•†ä¸šæ–°é—» (NewsAPI)
def fetch_newsapi_data(query, api_key, session):
    print(f"ğŸŒ æ­£åœ¨è°ƒç”¨ NewsAPI è·å–: {query}...")
    headers = {"X-Api-Key": api_key}
    params = {
        "q": query, "language": "zh", "pageSize": 10,
        "sortBy": "publishedAt", # æ”¹ä¸ºæŒ‰æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
        "searchIn": "title,description"
    }
    try:
        response = session.get(NEWS_API_URL, headers=headers, params=params, timeout=10)
        if response.status_code != 200:
            return ""
        data = response.json()
        if data.get('totalResults', 0) == 0:
            return ""
        
        summary = ""
        for article in data['articles'][:5]: # åªå–å‰5æ¡
            summary += f"- [NewsAPI] {article['title']} ({article['publishedAt'][:10]})\n"
        return summary
    except Exception as e:
        print(f"âš ï¸ NewsAPI è°ƒç”¨éƒ¨åˆ†å¤±è´¥: {e}")
        return ""

# B. ä¸­å›½å®˜æ–¹ä¿¡æº (Google News RSS Hack)
def fetch_official_sources():
    print("ğŸ‡¨ğŸ‡³ æ­£åœ¨ç›‘æ§ä¸­å›½å®˜æ–¹ä¿¡æº (é€šè¿‡ Google RSS)...")
    
    # å®šä¹‰æˆ‘ä»¬è¦ç›‘æ§çš„â€œå‚ç›´é¢†åŸŸâ€
    # site: è¯­æ³•è®©æˆ‘ä»¬èƒ½ç²¾å‡†å®šä½åˆ°ç‰¹å®šåŸŸåçš„å†…å®¹
    # when:2d é™åˆ¶ä¸ºè¿‡å» 48 å°æ—¶ï¼Œä¿è¯æ—¶æ•ˆæ€§
    targets = [
        {
            "name": "å¤–äº¤éƒ¨/å›½é˜²éƒ¨ (å®˜æ–¹è¡¨æ€)",
            "query": "site:mfa.gov.cn OR site:mod.gov.cn"
        },
        {
            "name": "è§£æ”¾å†›æŠ¥/å†›ç½‘ (å†›äº‹åŠ¨å‘)",
            "query": "site:81.cn OR site:chinamil.com.cn"
        },
        {
            "name": "æµ·äº‹å±€ (èˆªè¡Œè­¦å‘Š/æ¼”ä¹ )",
            "query": "site:msa.gov.cn AND (ç¦èˆª OR æ¼”ä¹  OR å®å¼¹)"
        }
    ]
    
    all_official_news = ""
    
    for target in targets:
        # æ„é€  Google News RSS URL
        # hl=zh-CN&gl=CN&ceid=CN:zh-CN å¼ºåˆ¶ä½¿ç”¨ç®€ä¸­/ä¸­å›½åŒºç»“æœ
        encoded_query = requests.utils.quote(target['query'] + " when:2d")
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-CN&gl=CN&ceid=CN:zh-CN"
        
        try:
            feed = feedparser.parse(rss_url)
            if not feed.entries:
                continue
                
            all_official_news += f"\nã€{target['name']}ã€‘:\n"
            # æ¯ä¸ªä¿¡æºå–å‰ 3 æ¡æœ€æ–°çš„
            for entry in feed.entries[:3]:
                title = entry.title
                # Google RSS çš„ link é€šå¸¸æ˜¯è·³è½¬é“¾æ¥ï¼Œæˆ‘ä»¬ä¸»è¦éœ€è¦æ ‡é¢˜å’Œæ‘˜è¦
                published = entry.published if 'published' in entry else "æœªçŸ¥æ—¶é—´"
                all_official_news += f"- {title} ({published})\n"
                
        except Exception as e:
            print(f"âš ï¸ RSS è·å–å¤±è´¥ ({target['name']}): {e}")
            
    return all_official_news

# --- 3. ç»¼åˆæƒ…æŠ¥è·å–å‡½æ•° ---

def get_combined_intelligence(category, news_api_query, news_api_key, session):
    """
    ç»„åˆ NewsAPI (å›½é™…/å•†ä¸š) å’Œ Google RSS (å®˜æ–¹/å‚ç›´) çš„æƒ…æŠ¥
    """
    final_text = ""
    
    # 1. è·å– NewsAPI æ•°æ®
    news_api_text = fetch_newsapi_data(news_api_query, news_api_key, session)
    if news_api_text:
        final_text += "=== å›½é™…ä¸å•†ä¸šåª’ä½“æŠ¥é“ ===\n" + news_api_text + "\n"
    
    # 2. è·å–å®˜æ–¹ä¿¡æº (ä»…å¯¹ç‰¹å®šç±»åˆ«å¯ç”¨ï¼Œé¿å…é‡å¤è¯·æ±‚)
    # åªæœ‰â€œå†›äº‹â€å’Œâ€œæ”¿æ²»â€ç±»åˆ«æ‰éœ€è¦å»æŸ¥å¤–äº¤éƒ¨å’Œæµ·äº‹å±€
    if category in ["å†›äº‹åå‹¤", "æ”¿æ²»èˆ†è®º"]:
        official_text = fetch_official_sources()
        if official_text:
            final_text += "=== ä¸­å›½å®˜æ–¹ä¸æ ¸å¿ƒä¿¡æº (è¿‡å»48å°æ—¶) ===\n" + official_text + "\n"
            
    if not final_text:
        return "æœªè·å–åˆ°ç›¸å…³æ–°é—»ã€‚"
        
    return final_text

# --- 4. LLM åˆ†æä¸ä¸»é€»è¾‘ (ä¸ V4 ä¿æŒä¸€è‡´ï¼Œå¾®è°ƒäº†è°ƒç”¨æ–¹å¼) ---

def get_triggered_indicators(category, news_text, indicators_list, api_key):
    category_indicators = [ind for ind in indicators_list if ind['category'] == category]
    if not category_indicators:
        return {"triggered_ids": [], "reasoning": "æ— æŒ‡æ ‡ã€‚"}

    system_prompt = f"""
    ä½ æ˜¯ä¸€åæƒ…æŠ¥åˆ†æå¸ˆã€‚è¯·æ ¹æ®æä¾›çš„ã€æ··åˆæƒ…æŠ¥æºã€‘ï¼ˆåŒ…å«å›½é™…åª’ä½“å’Œä¸­å›½å®˜æ–¹ä¿¡æºï¼‰åˆ¤æ–­æ˜¯å¦**æ˜ç¡®è§¦å‘**äº†é¢„è­¦æŒ‡æ ‡ã€‚
    
    æ³¨æ„ï¼š
    1. "å®˜æ–¹ä¿¡æº"éƒ¨åˆ†çš„å¯ä¿¡åº¦æé«˜ï¼Œå¦‚æœæµ·äº‹å±€(MSA)å‘å¸ƒäº†ç¦èˆªä»¤ï¼Œæˆ–è€…å¤–äº¤éƒ¨ä½¿ç”¨äº†æç«¯æªè¾ï¼Œè¯·åŠ¡å¿…è§¦å‘å¯¹åº”æŒ‡æ ‡ã€‚
    2. å¿…é¡»åŒºåˆ†"ä¾‹è¡Œ"ä¸"éä¾‹è¡Œ/å¤§è§„æ¨¡"ã€‚
    
    è¯·è¿”å› JSON:
    {{ "triggered_ids": ["ID1", "ID2"], "reasoning": "ç®€çŸ­åˆ†æ..." }}
    """
    
    user_prompt = f"""
    **ã€é¢„è­¦æŒ‡æ ‡ ({category})ã€‘**
    {json.dumps(category_indicators, indent=2, ensure_ascii=False)}

    **ã€æ··åˆæƒ…æŠ¥æºã€‘**
    "{news_text}"
    """
    
    headers = { "Content-Type": "application/json", "Authorization": f"Bearer {api_key}" }
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
        "response_format": {"type": "json_object"}
    }
    
    try:
        response = requests.post(DEEPSEEK_API_URL, headers=headers, data=json.dumps(payload), timeout=45)
        result = response.json()['choices'][0]['message']['content']
        return json.loads(result)
    except Exception as e:
        print(f"âŒ LLM åˆ†æå¤±è´¥ ({category}): {e}")
        return {"triggered_ids": [], "reasoning": f"åˆ†æå‡ºé”™: {e}"}

def main():
    if not DEEPSEEK_API_KEY or not NEWS_API_KEY:
        print("âŒ é”™è¯¯: ç¼ºå°‘ API å¯†é’¥ã€‚")
        exit(1)

    try:
        with open(INDICATORS_FILE, 'r', encoding='utf-8') as f:
            all_indicators_master = {ind['id']: ind for ind in json.load(f)}
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½æŒ‡æ ‡æ–‡ä»¶: {e}")
        exit(1)

    # åŠ è½½æ˜¨å¤©çŠ¶æ€
    try:
        with open(SCORES_FILE, 'r', encoding='utf-8') as f:
            yesterday_data = json.load(f)
            yesterday_state = yesterday_data.get('active_indicators', {})
    except:
        yesterday_state = {}

    session = create_retry_session()

    # å®šä¹‰æŸ¥è¯¢å…³é”®è¯
    queries = {
        "ç»æµé‡‘è": '(å°æ¹¾ OR ä¸­å›½) AND (ç»æµ OR è´¸æ˜“ OR åˆ¶è£ OR ä¾›åº”é“¾ OR èŠ¯ç‰‡)',
        "å†›äº‹åå‹¤": '(å°æ¹¾ OR ä¸­å›½) AND (å†›äº‹ OR æ¼”ä¹  OR è§£æ”¾å†› OR èˆªæ¯ OR ç¦èˆª)',
        "æ”¿æ²»èˆ†è®º": '(å°æ¹¾ OR ä¸­å›½) AND (å¤–äº¤ OR æ”¿æ²» OR è­¦å‘Š OR æ’¤ä¾¨)',
        "åœ¨åœ°ä½“æ„Ÿ(å¦é—¨)": 'å¦é—¨ AND (é˜²ç©º OR æ¼”ä¹  OR äº¤é€šç®¡åˆ¶)' # ä¾ç„¶ä¸»è¦é æ¨¡æ‹Ÿæˆ–æ‰‹åŠ¨ï¼ŒNewsAPIå¾ˆéš¾æŠ“åˆ°è¿™ä¸ª
    }

    # æ‰§è¡Œåˆ†æ
    results = {}
    print("--- å¼€å§‹å¤šæºæƒ…æŠ¥é‡‡é›†ä¸åˆ†æ ---")
    
    # ç»æµ
    text_econ = get_combined_intelligence("ç»æµé‡‘è", queries["ç»æµé‡‘è"], NEWS_API_KEY, session)
    results["econ"] = get_triggered_indicators("ç»æµé‡‘è", text_econ, list(all_indicators_master.values()), DEEPSEEK_API_KEY)
    
    # å†›äº‹ (é‡ç‚¹å¢å¼ºï¼šå®˜æ–¹ä¿¡æº)
    text_mil = get_combined_intelligence("å†›äº‹åå‹¤", queries["å†›äº‹åå‹¤"], NEWS_API_KEY, session)
    results["mil"] = get_triggered_indicators("å†›äº‹åå‹¤", text_mil, list(all_indicators_master.values()), DEEPSEEK_API_KEY)
    
    # æ”¿æ²» (é‡ç‚¹å¢å¼ºï¼šå®˜æ–¹ä¿¡æº)
    text_pol = get_combined_intelligence("æ”¿æ²»èˆ†è®º", queries["æ”¿æ²»èˆ†è®º"], NEWS_API_KEY, session)
    results["pol"] = get_triggered_indicators("æ”¿æ²»èˆ†è®º", text_pol, list(all_indicators_master.values()), DEEPSEEK_API_KEY)
    
    # æœ¬åœ° (ä¿æŒæ¨¡æ‹Ÿï¼Œæˆ–é€šè¿‡ NewsAPI ç¢°è¿æ°”)
    # æ³¨æ„ï¼šGoogle RSS ä¹Ÿå¯ä»¥æœ "site:xiamen.gov.cn" ä½†é€šå¸¸å¾ˆéš¾æœåˆ°å®æ—¶æ°‘é˜²ä¿¡æ¯
    text_local = "å¦é—¨æœ¬åœ°å±…æ°‘åé¦ˆï¼šæœ¬å‘¨é˜²ç©ºè­¦æŠ¥æµ‹è¯•æ˜¯å¹´åº¦ä¾‹è¡Œæµ‹è¯•ï¼Œè¶…å¸‚ç‰©èµ„ä¾›åº”å……è¶³ï¼Œæœªè§æŠ¢è´­ï¼Œç¤¾ä¼šç§©åºæ­£å¸¸ã€‚"
    results["local"] = get_triggered_indicators("åœ¨åœ°ä½“æ„Ÿ(å¦é—¨)", text_local, list(all_indicators_master.values()), DEEPSEEK_API_KEY)

    # --- çŠ¶æ€è®¡ç®— (è¡°å‡/åˆ·æ–°) ---
    today_triggered_ids = set()
    for res in results.values():
        today_triggered_ids.update(res.get('triggered_ids', []))
    
    today_state = {}
    today_str = str(datetime.now(timezone.utc).date())

    # 1. å¤„ç†æ—§æŒ‡æ ‡
    for ind_id, data in yesterday_state.items():
        if ind_id not in all_indicators_master: continue
        base_weight = all_indicators_master[ind_id]['weight']
        
        if ind_id in today_triggered_ids:
            # åˆ·æ–°
            today_state[ind_id] = { "base_weight": base_weight, "current_weight": base_weight, "triggered_on": today_str }
        else:
            # è¡°å‡
            new_weight = data['current_weight'] * DECAY_FACTOR
            if new_weight >= WEIGHT_FLOOR:
                today_state[ind_id] = { "base_weight": base_weight, "current_weight": new_weight, "triggered_on": data['triggered_on'] }

    # 2. å¤„ç†æ–°æŒ‡æ ‡
    for ind_id in today_triggered_ids:
        if ind_id not in today_state and ind_id in all_indicators_master:
            base_weight = all_indicators_master[ind_id]['weight']
            today_state[ind_id] = { "base_weight": base_weight, "current_weight": base_weight, "triggered_on": today_str }

    # 3. è®¡ç®—æ€»åˆ†
    total_possible = sum(i['weight'] for i in all_indicators_master.values())
    current_total = sum(i['current_weight'] for i in today_state.values())
    score = (current_total / total_possible) * 100 if total_possible > 0 else 0

    # 4. ä¿å­˜
    final_data = {
        "score": round(score),
        "total_indicators_possible": len(all_indicators_master),
        "active_indicators_count": len(today_state),
        "active_indicators": today_state,
        "category_reasoning": { k: v['reasoning'] for k, v in results.items() },
        "last_updated": datetime.now(timezone.utc).isoformat()
    }
    
    with open(SCORES_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, indent=4, ensure_ascii=False)
    
    print(f"âœ… åˆ†æå®Œæˆã€‚æ€»åˆ†: {round(score)}")

if __name__ == "__main__":
    main()
