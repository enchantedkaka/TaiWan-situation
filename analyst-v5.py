import json
import os
import requests
import feedparser
import datetime
from datetime import datetime, timezone
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# --- V5.3 é…ç½®åŒº (Gemini) ---
# è¯»å– Gemini API Key
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
NEWS_API_KEY = os.environ.get('NEWS_API_KEY')

# Gemini API URL (ä½¿ç”¨ gemini-2.0-flash æ¨¡å‹)
# æ³¨æ„ï¼šGemini API Key é€šå¸¸ç›´æ¥æ‹¼æ¥åœ¨ URL åï¼Œæˆ–è€…é€šè¿‡ header ä¼ é€’ (x-goog-api-key)
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

NEWS_API_URL = "https://newsapi.org/v2/everything"
INDICATORS_FILE = "indicators.json"
SCORES_FILE = "scores-v3.json"

DECAY_FACTOR = 0.75
WEIGHT_FLOOR = 1

# --- 1. ç½‘ç»œè¯·æ±‚åŸºç¡€ ---

def create_retry_session():
    session = requests.Session()
    retry_strategy = Retry(
        total=3, status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"], backoff_factor=1
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    return session

# --- 2. æ•°æ®è·å–æ¨¡å— (ä¿æŒä¸å˜) ---

def fetch_newsapi_data(query, api_key, session):
    print(f"ğŸŒ æ­£åœ¨è°ƒç”¨ NewsAPI è·å–: {query}...")
    headers = {"X-Api-Key": api_key}
    params = {
        "q": query, "language": "zh", "pageSize": 10,
        "sortBy": "publishedAt", 
        "searchIn": "title,description"
    }
    result = {"text": "", "articles": []}
    try:
        response = session.get(NEWS_API_URL, headers=headers, params=params, timeout=10)
        if response.status_code != 200: return result
        data = response.json()
        if data.get('totalResults', 0) == 0: return result
        
        summary = ""
        for article in data['articles'][:5]:
            title = article['title']
            date_str = article['publishedAt'][:10]
            source = article['source']['name']
            url = article['url']
            summary += f"- [NewsAPI] {title} ({date_str})\n"
            result["articles"].append({
                "title": title, "source": f"NewsAPI / {source}", "date": date_str, "url": url
            })
        result["text"] = summary
        return result
    except Exception as e:
        print(f"âš ï¸ NewsAPI è°ƒç”¨éƒ¨åˆ†å¤±è´¥: {e}")
        return result

def fetch_official_sources():
    print("ğŸ‡¨ğŸ‡³ æ­£åœ¨ç›‘æ§ä¸­å›½å®˜æ–¹ä¿¡æº (é€šè¿‡ Google RSS)...")
    targets = [
        { "name": "å¤–äº¤éƒ¨/å›½é˜²éƒ¨", "query": "site:mfa.gov.cn OR site:mod.gov.cn" },
        { "name": "è§£æ”¾å†›æŠ¥/å†›ç½‘", "query": "site:81.cn OR site:chinamil.com.cn" },
        { "name": "æµ·äº‹å±€", "query": "site:msa.gov.cn AND (ç¦èˆª OR æ¼”ä¹  OR å®å¼¹)" }
    ]
    result = {"text": "", "articles": []}
    all_text = ""
    for target in targets:
        encoded_query = requests.utils.quote(target['query'] + " when:2d")
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-CN&gl=CN&ceid=CN:zh-CN"
        try:
            feed = feedparser.parse(rss_url)
            if not feed.entries: continue
            all_text += f"\nã€{target['name']}ã€‘:\n"
            for entry in feed.entries[:3]:
                title = entry.title
                published = entry.published if 'published' in entry else "è¿‘æœŸ"
                link = entry.link if 'link' in entry else "#"
                try:
                    dt = datetime.strptime(published, "%a, %d %b %Y %H:%M:%S %Z")
                    date_str = dt.strftime("%Y-%m-%d")
                except:
                    date_str = published[:16]
                all_text += f"- {title} ({date_str})\n"
                result["articles"].append({
                    "title": title, "source": f"å®˜æ–¹ä¿¡æº / {target['name']}", "date": date_str, "url": link
                })
        except Exception as e:
            print(f"âš ï¸ RSS è·å–å¤±è´¥ ({target['name']}): {e}")
    result["text"] = all_text
    return result

def get_combined_intelligence(category, news_api_query, news_api_key, session):
    final_text = ""
    all_articles = []
    news_res = fetch_newsapi_data(news_api_query, news_api_key, session)
    if news_res["text"]:
        final_text += "=== å›½é™…ä¸å•†ä¸šåª’ä½“ ===\n" + news_res["text"] + "\n"
        all_articles.extend(news_res["articles"])
    if category in ["å†›äº‹åå‹¤", "æ”¿æ²»èˆ†è®º"]:
        off_res = fetch_official_sources()
        if off_res["text"]:
            final_text += "=== å®˜æ–¹ä¿¡æº ===\n" + off_res["text"] + "\n"
            all_articles.extend(off_res["articles"])
    if not final_text: final_text = "æœªè·å–åˆ°ç›¸å…³æ–°é—»ã€‚"
    return {"text": final_text, "articles": all_articles}

# --- 3. Gemini LLM åˆ†æ (æ ¸å¿ƒä¿®æ”¹) ---

def get_triggered_indicators(category, news_text, indicators_list, session):
    """
    ä½¿ç”¨ Google Gemini API è¿›è¡Œåˆ†æ
    """
    category_indicators = [ind for ind in indicators_list if ind['category'] == category]
    if not category_indicators: return {"triggered_ids": [], "reasoning": "æ— æŒ‡æ ‡ã€‚"}

    # æ„å»º Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€åæ•é”çš„æƒ…æŠ¥åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„ã€æ··åˆæƒ…æŠ¥æºã€‘åˆ¤æ–­æ˜¯å¦**æ˜ç¡®è§¦å‘**äº†é¢„è­¦æŒ‡æ ‡ã€‚

    **ã€é¢„è­¦æŒ‡æ ‡æ¸…å• ({category})ã€‘**
    {json.dumps(category_indicators, indent=2, ensure_ascii=False)}

    **ã€æ··åˆæƒ…æŠ¥æºã€‘**
    "{news_text}"

    **å…³é”®åˆ¤æ–­å‡†åˆ™ï¼š**
    1. **å®˜æ–¹ä¿¡æºæƒé‡æé«˜ï¼š** å³ä½¿æ˜¯â€œä¾‹è¡Œè®°è€…ä¼šâ€ï¼Œå¦‚æœå‘è¨€äººä½¿ç”¨äº†â€œæ€§è´¨æ¶åŠ£â€ã€â€œä¸¥é‡åæœâ€ã€â€œæ˜ç¡®äº¤ä»£â€ã€â€œååˆ¶â€ç­‰å¼ºç¡¬è¯æ±‡ï¼Œåº”è§†ä¸ºè§¦å‘â€œå¤–äº¤å¼ºç¡¬å£°æ˜â€ç±»æŒ‡æ ‡ (å¦‚ POL-2)ã€‚
    2. **åŒºåˆ†çƒˆåº¦ï¼š**
       - ä¸€èˆ¬æŠ—è®® -> ä¸è§¦å‘
       - å¼ºç¡¬è­¦å‘Š/ä¸¥æ­£äº¤æ¶‰/æ˜ç¡®äº¤ä»£ -> è§¦å‘ä¸­ä½æƒé‡æŒ‡æ ‡ (POL-2)
       - æˆ˜äº‰å¨èƒ/æœ€åé€šç‰’ -> è§¦å‘é«˜æƒé‡æŒ‡æ ‡ (POL-1)
    3. **å®å¯è¯¯æŠ¥ä¸å¯æ¼æŠ¥ï¼š** å¯¹äºå®˜æ–¹çš„å¼‚å¸¸è¡¨æ€ï¼Œä¿æŒè¾ƒé«˜çš„æ•æ„Ÿåº¦ã€‚

    **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
    è¯·ç›´æ¥è¿”å›ä¸€ä¸ªçº¯å‡€çš„ JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å« Markdown æ ¼å¼æ ‡è®°ï¼ˆå¦‚ ```json ... ```ï¼‰ã€‚
    JSON æ ¼å¼å¦‚ä¸‹ï¼š
    {{ "triggered_ids": ["ID1", "ID2"], "reasoning": "ç®€çŸ­åˆ†æ..." }}
    """

    # Gemini API Payload
    payload = {
        "contents": [{
            "parts": [{"text": prompt}]
        }],
        "generationConfig": {
            "response_mime_type": "application/json" # å¼ºåˆ¶è®© Gemini è¿”å› JSON
        }
    }
    
    headers = { "Content-Type": "application/json" }

    try:
        # ä½¿ç”¨ session å‘é€è¯·æ±‚
        response = session.post(GEMINI_API_URL, headers=headers, data=json.dumps(payload), timeout=45)
        
        if response.status_code != 200:
            print(f"âŒ Gemini API é”™è¯¯: {response.status_code} - {response.text}")
            return {"triggered_ids": [], "reasoning": f"APIé”™è¯¯: {response.status_code}"}

        # è§£æ Gemini å“åº”
        result_json = response.json()
        text_content = result_json['candidates'][0]['content']['parts'][0]['text']
        
        return json.loads(text_content)

    except Exception as e:
        print(f"âŒ LLM åˆ†æå¤±è´¥ ({category}): {e}")
        return {"triggered_ids": [], "reasoning": f"åˆ†æå‡ºé”™: {e}"}


# --- 4. ä¸»ç¨‹åº ---

def main():
    # æ£€æŸ¥ Gemini Key
    if not GEMINI_API_KEY:
        print("âŒ é”™è¯¯: ç¼ºå°‘ GEMINI_API_KEYã€‚è¯·åœ¨ GitHub Settings ä¸­è®¾ç½®ã€‚")
        exit(1)
    if not NEWS_API_KEY:
        print("âŒ é”™è¯¯: ç¼ºå°‘ NEWS_API_KEYã€‚")
        exit(1)

    try:
        with open(INDICATORS_FILE, 'r', encoding='utf-8') as f:
            all_indicators_master = {ind['id']: ind for ind in json.load(f)}
    except:
        print(f"âŒ æ— æ³•åŠ è½½ {INDICATORS_FILE}")
        exit(1)

    try:
        with open(SCORES_FILE, 'r', encoding='utf-8') as f:
            yesterday_state = json.load(f).get('active_indicators', {})
    except:
        yesterday_state = {}

    session = create_retry_session()
    queries = {
        "ç»æµé‡‘è": '(å°æ¹¾ OR ä¸­å›½) AND (ç»æµ OR è´¸æ˜“ OR åˆ¶è£ OR ä¾›åº”é“¾ OR èŠ¯ç‰‡)',
        "å†›äº‹åå‹¤": '(å°æ¹¾ OR ä¸­å›½) AND (å†›äº‹ OR æ¼”ä¹  OR è§£æ”¾å†› OR èˆªæ¯ OR ç¦èˆª)',
        "æ”¿æ²»èˆ†è®º": '(å°æ¹¾ OR ä¸­å›½) AND (å¤–äº¤ OR æ”¿æ²» OR è­¦å‘Š OR æ’¤ä¾¨)',
        "åœ¨åœ°ä½“æ„Ÿ(å¦é—¨)": 'å¦é—¨ AND (é˜²ç©º OR æ¼”ä¹  OR äº¤é€šç®¡åˆ¶)'
    }

    print("--- å¼€å§‹å¤šæºæƒ…æŠ¥é‡‡é›†ä¸åˆ†æ (V5.3 - Geminiç‰ˆ) ---")
    
    results = {}
    news_sources = {}
    
    for category in ["ç»æµé‡‘è", "å†›äº‹åå‹¤", "æ”¿æ²»èˆ†è®º", "åœ¨åœ°ä½“æ„Ÿ(å¦é—¨)"]:
        key_map = {"ç»æµé‡‘è": "econ", "å†›äº‹åå‹¤": "mil", "æ”¿æ²»èˆ†è®º": "pol", "åœ¨åœ°ä½“æ„Ÿ(å¦é—¨)": "local"}
        key = key_map[category]
        
        if category == "åœ¨åœ°ä½“æ„Ÿ(å¦é—¨)":
            intel = {"text": "å¦é—¨æœ¬åœ°å±…æ°‘åé¦ˆï¼šæœ¬å‘¨é˜²ç©ºè­¦æŠ¥æµ‹è¯•æ˜¯å¹´åº¦ä¾‹è¡Œæµ‹è¯•ï¼Œè¶…å¸‚ç‰©èµ„ä¾›åº”å……è¶³ï¼Œæœªè§æŠ¢è´­ï¼Œç¤¾ä¼šç§©åºæ­£å¸¸ã€‚", "articles": []}
        else:
            intel = get_combined_intelligence(category, queries[category], NEWS_API_KEY, session)
            
        news_sources[key] = intel["articles"]
        
        # è°ƒç”¨ Gemini è¿›è¡Œåˆ†æ
        results[key] = get_triggered_indicators(category, intel["text"], list(all_indicators_master.values()), session)

    # --- çŠ¶æ€è®¡ç®— (ä¸ä¹‹å‰ä¸€è‡´) ---
    today_triggered_ids = set()
    for res in results.values():
        today_triggered_ids.update(res.get('triggered_ids', []))
    
    today_state = {}
    today_str = str(datetime.now(timezone.utc).date())

    for ind_id, data in yesterday_state.items():
        if ind_id not in all_indicators_master: continue
        base_weight = all_indicators_master[ind_id]['weight']
        if ind_id in today_triggered_ids:
            today_state[ind_id] = { "base_weight": base_weight, "current_weight": base_weight, "triggered_on": today_str }
        else:
            new_weight = data['current_weight'] * DECAY_FACTOR
            if new_weight >= WEIGHT_FLOOR:
                today_state[ind_id] = { "base_weight": base_weight, "current_weight": new_weight, "triggered_on": data['triggered_on'] }

    for ind_id in today_triggered_ids:
        if ind_id not in today_state and ind_id in all_indicators_master:
            base_weight = all_indicators_master[ind_id]['weight']
            today_state[ind_id] = { "base_weight": base_weight, "current_weight": base_weight, "triggered_on": today_str }

    total_possible = sum(i['weight'] for i in all_indicators_master.values())
    current_total = sum(i['current_weight'] for i in today_state.values())
    score = (current_total / total_possible) * 100 if total_possible > 0 else 0

    final_data = {
        "score": round(score),
        "total_indicators_possible": len(all_indicators_master),
        "active_indicators_count": len(today_state),
        "active_indicators": today_state,
        "category_reasoning": { k: v['reasoning'] for k, v in results.items() },
        "news_sources": news_sources,
        "last_updated": datetime.now(timezone.utc).isoformat()
    }
    
    with open(SCORES_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, indent=4, ensure_ascii=False)
    
    print(f"âœ… åˆ†æå®Œæˆã€‚æ€»åˆ†: {round(score)}")

if __name__ == "__main__":
    main()
